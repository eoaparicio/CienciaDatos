{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio 32_[Arquetipo_de_Feature_Engineering_para_Vision_Artificial].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F1HodeYsT3f"
      },
      "source": [
        "#Autor: Alonso Melgarejo\n",
        "#Contacto: alonsoraulmgs@gmail.com\n",
        "#Copyright: Big Data Academy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLc7_0z3sX03"
      },
      "source": [
        "# Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppWaottBs4_2",
        "outputId": "2536f5c3-bb27-433d-bc30-9e3286d8ed1c"
      },
      "source": [
        "#Instalamos las librerías\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-nightly\n",
            "  Downloading tf_nightly-2.8.0.dev20211021-cp37-cp37m-manylinux2010_x86_64.whl (488.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 488.6 MB 28 kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting libclang>=9.0.1\n",
            "  Downloading libclang-12.0.0-py2.py3-none-manylinux1_x86_64.whl (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 236 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Collecting keras-nightly~=2.8.0.dev\n",
            "  Downloading keras_nightly-2.8.0.dev2021102107-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.37.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.41.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Collecting tf-estimator-nightly~=2.8.0.dev\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021102108-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting tb-nightly~=2.7.0.a\n",
            "  Downloading tb_nightly-2.7.0a20211013-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tf-nightly) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.7.0.a->tf-nightly) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.7.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly) (3.6.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-io-gcs-filesystem, tb-nightly, libclang, keras-nightly, tf-nightly\n",
            "Successfully installed keras-nightly-2.8.0.dev2021102107 libclang-12.0.0 tb-nightly-2.7.0a20211013 tensorflow-io-gcs-filesystem-0.21.0 tf-estimator-nightly-2.8.0.dev2021102108 tf-nightly-2.8.0.dev20211021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P5N6POmsblo"
      },
      "source": [
        "#Importamos las librerías\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpN7Yn-Fspd-"
      },
      "source": [
        "# Conexión al repositorio de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6mMLolnsYbG",
        "outputId": "a989578e-ab9c-44bb-dd06-933a6bfe3f11"
      },
      "source": [
        "#Nos conectamos al repositorio de datos\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj2ztQ2Nsy5G"
      },
      "source": [
        "# Configuración de rutas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFE__vxs0JH"
      },
      "source": [
        "#Ruta de la carpeta de imágenes de entrenamiento\n",
        "ruta_imagenes_entrenamiento = '/content/drive/MyDrive/Data/IMAGES_RAW_SPLIT/train'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6rZlD5HunJV"
      },
      "source": [
        "#Ruta de la carpeta de imágenes de validacion\n",
        "ruta_imagenes_validacion = '/content/drive/MyDrive/Data/IMAGES_RAW_SPLIT/test'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNgXksnytBao"
      },
      "source": [
        "#Ruta en donde se almacenarán los tensores\n",
        "ruta_tensores = '/content/drive/MyDrive/Data/TENSORS'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-S5S6OGtR4b"
      },
      "source": [
        "#Ruta en donde se almacenarán los tensores de entrenamiento\n",
        "ruta_tensores_entrenamiento = '/content/drive/MyDrive/Data/TENSORS/train'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wYDKqj_tTiP"
      },
      "source": [
        "#Ruta en donde se almacenarán los tensores de validacion\n",
        "ruta_tensores_validacion = '/content/drive/MyDrive/Data/TENSORS/test'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtwKtA-ktvEE"
      },
      "source": [
        "# Configuración de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LmBCliutxWX"
      },
      "source": [
        "#Tipo de canal de color\n",
        "color_mode=\"rgb\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gforjvUmt1jv"
      },
      "source": [
        "#Tamaño de las imágenes en píxeles\n",
        "image_size=(32, 32)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru1vU2EWt1mK"
      },
      "source": [
        "#El dataset puede tener imágenes que no sean de 32x32, en ese caso se redimenzionaran\n",
        "interpolation=\"bilinear\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGrOMdBt1oc"
      },
      "source": [
        "#Es el parámetro que nos evita el colapso de la memoria RAM, procesaremos las imágenes de 10 en 10\n",
        "batch_size=10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnGG3NL3t1q2"
      },
      "source": [
        "#La carpeta divide las imágenes en subcategorías, al activar esta opción le estamos diciendo que cada subcarpeta es una categoría\n",
        "labels=\"inferred\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kog-F4S9t1tI"
      },
      "source": [
        "#Cada categoría es etiquetada con un número (0, 1, 2)\n",
        "label_mode=\"int\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpVj6SGit1wg"
      },
      "source": [
        "#Finalmente, al momento de tensorizar las imágenes, aleatoriezamos su orden para leerlas en desorden\n",
        "shuffle=True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2DUFr1vsukN"
      },
      "source": [
        "# Funciones utilitarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhOxyYZNtjdW"
      },
      "source": [
        "#Funcion para guardar imagenes como tensores en disco duro\n",
        "def almacenar_en_disco_como_tensores(tensor, ruta):\n",
        "  #Si existe, la ruta, la borramos\n",
        "  if os.path.exists(ruta):\n",
        "    shutil.rmtree(ruta)\n",
        "\n",
        "  #Creamos la carpeta en donde guardaremos los archivos de tensores\n",
        "  os.mkdir(ruta)\n",
        "  \n",
        "  #Iteramos los tensores leídos\n",
        "  index = 0\n",
        "  for tensor_features, tensor_labels in iter(tensor):\n",
        "    #Convertimos los features a array\n",
        "    tensor_features_numpy = tensor_features.numpy()\n",
        "\n",
        "    #Convertimos los labels a categóricos\n",
        "    tensor_labels_categorico = to_categorical(tensor_labels, num_classes = len(tensor.class_names))\n",
        "\n",
        "    #Colocamos los datos en un diccionario\n",
        "    dataset = {}\n",
        "    dataset['features'] = tensor_features_numpy\n",
        "    dataset['labels'] = tensor_labels_categorico\n",
        "    dataset['metadata'] = tensor.class_names\n",
        "\n",
        "    #Guardamos los datos tensoriales en un archivo\n",
        "    dataset_numpy = np.array(dataset)\n",
        "    np.savez(ruta+'/tensor_' + str(index), dataset_numpy)\n",
        "\n",
        "    index = index + 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8qUsVdBtpDq"
      },
      "source": [
        "# Programa [Tensorizar datos de entrenamiento]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SfV-QK9u-1Y"
      },
      "source": [
        "#Verificamos si la carpeta de tensores existe\n",
        "#Si existe, la borramos\n",
        "if os.path.exists(ruta_tensores):\n",
        "  shutil.rmtree(ruta_tensores)\n",
        "\n",
        "#Creamos la ruta\n",
        "os.mkdir(ruta_tensores)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U98v3V2Utqc1",
        "outputId": "1c316fe9-7997-4c1d-e530-9e026c1cf5ed"
      },
      "source": [
        "#Leemos la carpeta de imágenes de entrenamiento como tensores\n",
        "tensor_entrenamiento = image_dataset_from_directory(\n",
        "    ruta_imagenes_entrenamiento, #Ruta de la carpeta con imágenes\n",
        "    color_mode=color_mode, #Tipo de canal de color\n",
        "    image_size=image_size, #Tamaño de las imágenes\n",
        "    interpolation=interpolation, #El dataset puede tener imágenes que no sean de 32x32, en ese caso se redimenzionaran\n",
        "    batch_size=batch_size, #Es el parámetro que nos evita el colapso de la memoria RAM, procesaremos las imágenes de 10 en 10\n",
        "    labels=labels, #La carpeta divide las imágenes en subcategorías, al activar esta opción le estamos diciendo que cada subcarpeta es una categoría\n",
        "    label_mode=label_mode, #Cada categoría es etiquetada con un número (0, 1, 2)\n",
        "    shuffle=shuffle #Finalmente, al momento de tensorizar las imágenes, aleatoriezamos su orden para leerlas en desorden\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 82 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAMUhmxuzIO"
      },
      "source": [
        "#Creamos la carpeta en donde guardaremos los archivos de tensores\n",
        "os.mkdir(ruta_tensores_entrenamiento)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC2U2zfrueIg"
      },
      "source": [
        "#Guardamos el tensor en la carpeta\n",
        "almacenar_en_disco_como_tensores(tensor_entrenamiento, ruta_tensores_entrenamiento)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZV6j4l5vMhN"
      },
      "source": [
        "# Programa [Tensorizar datos de entrenamiento]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2-W_uwKvOU0",
        "outputId": "5e1eee7a-acd3-4947-8e8a-974bdf0b8e9c"
      },
      "source": [
        "#Leemos la carpeta de imágenes de validacio como tensores\n",
        "tensor_validacion = image_dataset_from_directory(\n",
        "    ruta_imagenes_validacion, #Ruta de la carpeta con imágenes\n",
        "    color_mode=color_mode, #Tipo de canal de color\n",
        "    image_size=image_size, #Tamaño de las imágenes\n",
        "    interpolation=interpolation, #El dataset puede tener imágenes que no sean de 32x32, en ese caso se redimenzionaran\n",
        "    batch_size=batch_size, #Es el parámetro que nos evita el colapso de la memoria RAM, procesaremos las imágenes de 10 en 10\n",
        "    labels=labels, #La carpeta divide las imágenes en subcategorías, al activar esta opción le estamos diciendo que cada subcarpeta es una categoría\n",
        "    label_mode=label_mode, #Cada categoría es etiquetada con un número (0, 1, 2)\n",
        "    shuffle=shuffle #Finalmente, al momento de tensorizar las imágenes, aleatoriezamos su orden para leerlas en desorden\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTHGaKNvPEE"
      },
      "source": [
        "#Creamos la carpeta en donde guardaremos los archivos de tensores\n",
        "os.mkdir(ruta_tensores_validacion)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKGjfq_tvPGb"
      },
      "source": [
        "#Guardamos el tensor en la carpeta\n",
        "almacenar_en_disco_como_tensores(tensor_validacion, ruta_tensores_validacion)"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}