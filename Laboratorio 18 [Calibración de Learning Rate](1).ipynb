{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laboratorio_18_[Calibración_de_Learning_Rate]_v1_0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-VGe8CSzeOs"
      },
      "source": [
        "# Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DqYdKoPzivX"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452_Vvx9zrOn"
      },
      "source": [
        "# Conexión al repositorio de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTujE2_yzqx5",
        "outputId": "efdc5213-3327-45ec-ee24-ca612fe09eba"
      },
      "source": [
        "#Accedemos a Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRg5f2pCznXL"
      },
      "source": [
        "# Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ANwZ_0qOzovZ",
        "outputId": "b3eddff9-49a3-445a-d79f-b4c606b6dc43"
      },
      "source": [
        "#Leemos los datos\n",
        "#Se trata de un dataset que describe las características de billetes verdaderos y falsos\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data/billetes.csv')\n",
        "df\n",
        "\n",
        "#No entraremos mucho en los detalles de qué significa cada variable\n",
        "#Cada variable indica una característica del billete\n",
        "#El label \"class\" determina si un billete es o no falso"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variace</th>\n",
              "      <th>skewness</th>\n",
              "      <th>curtosis</th>\n",
              "      <th>entropy</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.62160</td>\n",
              "      <td>8.66610</td>\n",
              "      <td>-2.8073</td>\n",
              "      <td>-0.44699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.54590</td>\n",
              "      <td>8.16740</td>\n",
              "      <td>-2.4586</td>\n",
              "      <td>-1.46210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.86600</td>\n",
              "      <td>-2.63830</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>0.10645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.45660</td>\n",
              "      <td>9.52280</td>\n",
              "      <td>-4.0112</td>\n",
              "      <td>-3.59440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.32924</td>\n",
              "      <td>-4.45520</td>\n",
              "      <td>4.5718</td>\n",
              "      <td>-0.98880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367</th>\n",
              "      <td>0.40614</td>\n",
              "      <td>1.34920</td>\n",
              "      <td>-1.4501</td>\n",
              "      <td>-0.55949</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>-1.38870</td>\n",
              "      <td>-4.87730</td>\n",
              "      <td>6.4774</td>\n",
              "      <td>0.34179</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1369</th>\n",
              "      <td>-3.75030</td>\n",
              "      <td>-13.45860</td>\n",
              "      <td>17.5932</td>\n",
              "      <td>-2.77710</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>-3.56370</td>\n",
              "      <td>-8.38270</td>\n",
              "      <td>12.3930</td>\n",
              "      <td>-1.28230</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1371</th>\n",
              "      <td>-2.54190</td>\n",
              "      <td>-0.65804</td>\n",
              "      <td>2.6842</td>\n",
              "      <td>1.19520</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1372 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      variace  skewness  curtosis  entropy  class\n",
              "0     3.62160   8.66610   -2.8073 -0.44699      0\n",
              "1     4.54590   8.16740   -2.4586 -1.46210      0\n",
              "2     3.86600  -2.63830    1.9242  0.10645      0\n",
              "3     3.45660   9.52280   -4.0112 -3.59440      0\n",
              "4     0.32924  -4.45520    4.5718 -0.98880      0\n",
              "...       ...       ...       ...      ...    ...\n",
              "1367  0.40614   1.34920   -1.4501 -0.55949      1\n",
              "1368 -1.38870  -4.87730    6.4774  0.34179      1\n",
              "1369 -3.75030 -13.45860   17.5932 -2.77710      1\n",
              "1370 -3.56370  -8.38270   12.3930 -1.28230      1\n",
              "1371 -2.54190  -0.65804    2.6842  1.19520      1\n",
              "\n",
              "[1372 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mlvKlqVz7tS"
      },
      "source": [
        "# Definición de \"features\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86aFqKobz8wQ",
        "outputId": "d138577a-f743-4be3-dfb8-d327829de1b8"
      },
      "source": [
        "#Definimos los features\n",
        "x = df[['variace', 'skewness', 'curtosis', 'entropy']].values\n",
        "x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3.6216 ,   8.6661 ,  -2.8073 ,  -0.44699],\n",
              "       [  4.5459 ,   8.1674 ,  -2.4586 ,  -1.4621 ],\n",
              "       [  3.866  ,  -2.6383 ,   1.9242 ,   0.10645],\n",
              "       ...,\n",
              "       [ -3.7503 , -13.4586 ,  17.5932 ,  -2.7771 ],\n",
              "       [ -3.5637 ,  -8.3827 ,  12.393  ,  -1.2823 ],\n",
              "       [ -2.5419 ,  -0.65804,   2.6842 ,   1.1952 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiLTRK4B0FEP"
      },
      "source": [
        "#En el caso de los features, vamos a escalarlos con valores entre 0 y 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn2NvdK00HwN"
      },
      "source": [
        "#Importamos la librería para escalar\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzZlT1Wl0JFh",
        "outputId": "b6577bea-f219-4379-e30c-9b8544f4c704"
      },
      "source": [
        "#Escalamos\n",
        "x = scale(x)\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.12180565,  1.14945512, -0.97597007,  0.35456135],\n",
              "       [ 1.44706568,  1.06445293, -0.89503626, -0.12876744],\n",
              "       [ 1.20780971, -0.77735215,  0.12221838,  0.61807317],\n",
              "       ...,\n",
              "       [-1.47235682, -2.62164576,  3.75901744, -0.75488418],\n",
              "       [-1.40669251, -1.75647104,  2.552043  , -0.04315848],\n",
              "       [-1.04712236, -0.43982168,  0.29861555,  1.1364645 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Za_Wy2K0BAz"
      },
      "source": [
        "# Definición de \"labels\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO0Rd3X40CTz",
        "outputId": "9771d958-cecd-486c-f033-27e18455ca67"
      },
      "source": [
        "#Definimos los labels\n",
        "y = df['class'].values\n",
        "y"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMxhPprr0LkX"
      },
      "source": [
        "# Un modelo de Machine Learning clásico: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yacl_1zx0Ps5"
      },
      "source": [
        "#Por un momento vamos a usar otro modelo diferente a los de Deep Learning\n",
        "#Vamos a usar un RandomForest\n",
        "#Un RandomForest es un conjunto de árboles de decisión\n",
        "#No nos importará cómo se crea, sólo lo usaremos para compararlo con la red neuronal\n",
        "\n",
        "#Importamos la librería\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR_d4moT0R2k"
      },
      "source": [
        "#Creamos el modelo\n",
        "model = RandomForestClassifier()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elAOPJJc0Tqn",
        "outputId": "7b543a50-059c-47f2-f77d-22fe2ec84792"
      },
      "source": [
        "#Aplicamos validación cruzada para ver el ratio de predicción\n",
        "\n",
        "#Importamos la función de validación cruzada\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Por defecto, la función realiza 5 validaciones\n",
        "cross_val_score(model, x, y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99636364, 0.99636364, 0.98905109, 0.99635036, 0.99635036])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZZjFmur0jy0"
      },
      "source": [
        "# Generación de una neurona con ratio de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnsrqUzg1AcS"
      },
      "source": [
        "#Importamos la librería para dividir los datos\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Dividimos los datos en datos de entrenamiento (x_train, y_train) y datos de validación (x_test, y_test)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEOJFXXC0lv6"
      },
      "source": [
        "#Importamos las librerías de Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "#Importamos un optimizador\n",
        "#Ya sabemos que podemos usar el método de gradiente descendiente para encontrar el punto en dónde se mimice el error en nuestra función de costo\n",
        "#Usaremos una gradiente descendiente conocida como SDG: Stocastic Descendent Gradiente (Gradiente descedente estocástica)\n",
        "#¿Qué significa?, al decir que es estocástica significa que estamos colocando el punto inicial de evaluación de manera aleatoria\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7kJauNO0oLY"
      },
      "source": [
        "#Instaciamos un modelo de machine learning vacío con \"Sequential\"\n",
        "model = Sequential()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8bg9nLy0s6Q"
      },
      "source": [
        "#Agregamos sólo 1 neurona con 4 entradas\n",
        "#Como estamos frente a un problema de clasificación binaria, la F.A. más adecuada es la \"sigmoid\"\n",
        "model.add(Dense(1, input_shape=(4,), activation='sigmoid'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouXtFu_403-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42a0c70-f67c-4da4-ea22-c0d5465dc9d4"
      },
      "source": [
        "#Compilamos probando un \"learning rate\" (lr) pequeño de 0.01\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=SGD(lr=0.01),\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plW_Q1Y1TeB",
        "outputId": "8c2f106a-1bfe-445a-e18c-f0d2c5d1cd07"
      },
      "source": [
        "#Entrenamos el modelo\n",
        "#Esta vez al momento de entrenar, vamos a guardar la descripción del entrenamiento\n",
        "#Configuramos 10 iteraciones\n",
        "descripcion_de_entrenamiento = model.fit(x_train, y_train, epochs = 10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "35/35 [==============================] - 1s 1ms/step - loss: 0.9486 - accuracy: 0.3345\n",
            "Epoch 2/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.8228 - accuracy: 0.4047\n",
            "Epoch 3/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.5141\n",
            "Epoch 4/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.7129\n",
            "Epoch 5/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.8778\n",
            "Epoch 6/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.5356 - accuracy: 0.9307\n",
            "Epoch 7/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.9426\n",
            "Epoch 8/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.9371\n",
            "Epoch 9/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.9362\n",
            "Epoch 10/10\n",
            "35/35 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.9325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOn-W91B1Xjs",
        "outputId": "e97f6975-987f-46a0-b1b4-74fb043f01a3"
      },
      "source": [
        "#Dentro de esta variable encontraremos el accuracy de entrenamiento y el error de ganancia de descubrimiento de patrones al entrenar (loss)\n",
        "descripcion_de_entrenamiento.history"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.3345487713813782,\n",
              "  0.40474021434783936,\n",
              "  0.5141294598579407,\n",
              "  0.7128532528877258,\n",
              "  0.8778486847877502,\n",
              "  0.9307201504707336,\n",
              "  0.9425706267356873,\n",
              "  0.9371011853218079,\n",
              "  0.936189591884613,\n",
              "  0.9325432777404785],\n",
              " 'loss': [0.9485770463943481,\n",
              "  0.8228261470794678,\n",
              "  0.7231215238571167,\n",
              "  0.6445474624633789,\n",
              "  0.5832316875457764,\n",
              "  0.5356399416923523,\n",
              "  0.498688668012619,\n",
              "  0.4686990976333618,\n",
              "  0.44410961866378784,\n",
              "  0.42345643043518066]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQxfM7iY1cuP",
        "outputId": "c2d6e600-505b-4602-fea1-b379f46263b5"
      },
      "source": [
        "#Dentro de esta variable también tenemos el número de iteraciones que nuestro modelo ha hecho\n",
        "descripcion_de_entrenamiento.epoch"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1dx7W-i1j_y",
        "outputId": "0ff05cd7-9fdb-4616-e93e-e93ca0159167"
      },
      "source": [
        "#Evaluamos el modelo con los datos de entrenamiento\n",
        "accuracy = model.evaluate(x_test, y_test)\n",
        "accuracy"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.9418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40964755415916443, 0.9418181777000427]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kzDhK3Wk1n2b",
        "outputId": "70965f55-2795-4da9-bee0-8667da2a0e2c"
      },
      "source": [
        "#Colocamos los datos en un dataframe de pandas\n",
        "#El dataframe tendrá dos variables: accuracy y loss\n",
        "dfDescripcion = pd.DataFrame(\n",
        "    descripcion_de_entrenamiento.history,\n",
        "    index = descripcion_de_entrenamiento.epoch\n",
        ")\n",
        "\n",
        "dfDescripcion"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.948577</td>\n",
              "      <td>0.334549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.822826</td>\n",
              "      <td>0.404740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.723122</td>\n",
              "      <td>0.514129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.644547</td>\n",
              "      <td>0.712853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583232</td>\n",
              "      <td>0.877849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.535640</td>\n",
              "      <td>0.930720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.498689</td>\n",
              "      <td>0.942571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.468699</td>\n",
              "      <td>0.937101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.444110</td>\n",
              "      <td>0.936190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.423456</td>\n",
              "      <td>0.932543</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy\n",
              "0  0.948577  0.334549\n",
              "1  0.822826  0.404740\n",
              "2  0.723122  0.514129\n",
              "3  0.644547  0.712853\n",
              "4  0.583232  0.877849\n",
              "5  0.535640  0.930720\n",
              "6  0.498689  0.942571\n",
              "7  0.468699  0.937101\n",
              "8  0.444110  0.936190\n",
              "9  0.423456  0.932543"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2DEHotW1s-6"
      },
      "source": [
        "# Calibración del ratio de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubSL6Sqp1vNo"
      },
      "source": [
        "#¿El valor de lr = 0.01 será muy grande o muy pequeño?\n",
        "#Vamos a calibrar el valor de lr para saberlo"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZPmxqB1w-U"
      },
      "source": [
        "#Probaremos diferentes valores para lr\n",
        "array_lr = [0.01, 0.05, 0.1, 0.5]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsbCvGQ91x2w"
      },
      "source": [
        "#Creamos un array en donde guardaremos las descripciones de cada entrenamiento\n",
        "array_descripciones = []"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz2KCQcL10JH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90402e2-a9aa-4adc-a573-6e93f592be0a"
      },
      "source": [
        "#Iteramos cada calibración\n",
        "for lr in array_lr:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(1, input_shape=(4,), activation='sigmoid'))\n",
        "  \n",
        "  #Agregamos el \"lr\" de la calibración\n",
        "  model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=SGD(lr=lr),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  \n",
        "  #Entrenamos la neurona\n",
        "  #Para evitar que el output de entrenamiento se muestre en pantalla desactivamos la variable \"verbose\"\n",
        "  descripcion_de_entrenamiento = model.fit(x_train, y_train, epochs = 10, batch_size=16, verbose=0)\n",
        "\n",
        "  #Convertimos la descripción del entrenamiento en un dataframe\n",
        "  df = pd.DataFrame(\n",
        "      descripcion_de_entrenamiento.history,\n",
        "      index = descripcion_de_entrenamiento.epoch\n",
        "  )\n",
        "\n",
        "  #Agregamos el dataframe a la lista de descripciones de entrenamiento\n",
        "  array_descripciones.append(df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "8GbeHrEO1_Ez",
        "outputId": "efd612f5-11b4-4889-e417-db72eb5e0a1d"
      },
      "source": [
        "#Dentro de nuestro array de descripciones tendremos las descripciones de los cuatro entrenamientos con diferentes \"lr\"\n",
        "\n",
        "#El primer entrenamiento con lr = 0.01\n",
        "array_descripciones[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.005324</td>\n",
              "      <td>0.399271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.783567</td>\n",
              "      <td>0.534184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630632</td>\n",
              "      <td>0.680036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.525974</td>\n",
              "      <td>0.804011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.453674</td>\n",
              "      <td>0.868733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.919781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.959891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.337906</td>\n",
              "      <td>0.969918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.316213</td>\n",
              "      <td>0.971741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.298730</td>\n",
              "      <td>0.969918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy\n",
              "0  1.005324  0.399271\n",
              "1  0.783567  0.534184\n",
              "2  0.630632  0.680036\n",
              "3  0.525974  0.804011\n",
              "4  0.453674  0.868733\n",
              "5  0.402829  0.919781\n",
              "6  0.365800  0.959891\n",
              "7  0.337906  0.969918\n",
              "8  0.316213  0.971741\n",
              "9  0.298730  0.969918"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "19xmPUJ82Axv",
        "outputId": "1eef949a-1b35-45bb-d3ac-b8c72c7f6170"
      },
      "source": [
        "#El segundo entrenamiento con lr = 0.05\n",
        "array_descripciones[1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.430074</td>\n",
              "      <td>0.908842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.281025</td>\n",
              "      <td>0.971741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.231607</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183550</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.168534</td>\n",
              "      <td>0.970830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.156577</td>\n",
              "      <td>0.970830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.146815</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.138552</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.131511</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy\n",
              "0  0.430074  0.908842\n",
              "1  0.281025  0.971741\n",
              "2  0.231607  0.968095\n",
              "3  0.203333  0.968095\n",
              "4  0.183550  0.968095\n",
              "5  0.168534  0.970830\n",
              "6  0.156577  0.970830\n",
              "7  0.146815  0.972653\n",
              "8  0.138552  0.972653\n",
              "9  0.131511  0.972653"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeIXIhhZ2Cp9",
        "outputId": "1a7603ca-3e9a-459b-9e62-54e2f92372cf"
      },
      "source": [
        "#Esto es un array de dataframes\n",
        "type(array_descripciones)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tBSR7h8H2D93",
        "outputId": "8da6a44b-28dc-401d-e523-66750617144d"
      },
      "source": [
        "#Vamos a fusionar los cuatro dataframes en uno solo\n",
        "#Para eso usamos la función \"concat\" de pandas\n",
        "#Podríamos fusionar cada dataframe como si fuese un registro de la siguiente manera\n",
        "dfDescripcion = pd.concat(array_descripciones)\n",
        "dfDescripcion"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.005324</td>\n",
              "      <td>0.399271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.783567</td>\n",
              "      <td>0.534184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630632</td>\n",
              "      <td>0.680036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.525974</td>\n",
              "      <td>0.804011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.453674</td>\n",
              "      <td>0.868733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.919781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.959891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.337906</td>\n",
              "      <td>0.969918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.316213</td>\n",
              "      <td>0.971741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.298730</td>\n",
              "      <td>0.969918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.430074</td>\n",
              "      <td>0.908842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.281025</td>\n",
              "      <td>0.971741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.231607</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.183550</td>\n",
              "      <td>0.968095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.168534</td>\n",
              "      <td>0.970830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.156577</td>\n",
              "      <td>0.970830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.146815</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.138552</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.131511</td>\n",
              "      <td>0.972653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.335991</td>\n",
              "      <td>0.945305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.228656</td>\n",
              "      <td>0.958067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.184308</td>\n",
              "      <td>0.961714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.157476</td>\n",
              "      <td>0.969918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.139054</td>\n",
              "      <td>0.970830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.125747</td>\n",
              "      <td>0.973564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.115612</td>\n",
              "      <td>0.976299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.107558</td>\n",
              "      <td>0.977211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.101016</td>\n",
              "      <td>0.978122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.095641</td>\n",
              "      <td>0.979034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.279429</td>\n",
              "      <td>0.894257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.121337</td>\n",
              "      <td>0.973564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.089055</td>\n",
              "      <td>0.978122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.075063</td>\n",
              "      <td>0.979945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.066499</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.060816</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.056616</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.053365</td>\n",
              "      <td>0.984503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.050958</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.048692</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy\n",
              "0  1.005324  0.399271\n",
              "1  0.783567  0.534184\n",
              "2  0.630632  0.680036\n",
              "3  0.525974  0.804011\n",
              "4  0.453674  0.868733\n",
              "5  0.402829  0.919781\n",
              "6  0.365800  0.959891\n",
              "7  0.337906  0.969918\n",
              "8  0.316213  0.971741\n",
              "9  0.298730  0.969918\n",
              "0  0.430074  0.908842\n",
              "1  0.281025  0.971741\n",
              "2  0.231607  0.968095\n",
              "3  0.203333  0.968095\n",
              "4  0.183550  0.968095\n",
              "5  0.168534  0.970830\n",
              "6  0.156577  0.970830\n",
              "7  0.146815  0.972653\n",
              "8  0.138552  0.972653\n",
              "9  0.131511  0.972653\n",
              "0  0.335991  0.945305\n",
              "1  0.228656  0.958067\n",
              "2  0.184308  0.961714\n",
              "3  0.157476  0.969918\n",
              "4  0.139054  0.970830\n",
              "5  0.125747  0.973564\n",
              "6  0.115612  0.976299\n",
              "7  0.107558  0.977211\n",
              "8  0.101016  0.978122\n",
              "9  0.095641  0.979034\n",
              "0  0.279429  0.894257\n",
              "1  0.121337  0.973564\n",
              "2  0.089055  0.978122\n",
              "3  0.075063  0.979945\n",
              "4  0.066499  0.982680\n",
              "5  0.060816  0.982680\n",
              "6  0.056616  0.982680\n",
              "7  0.053365  0.984503\n",
              "8  0.050958  0.983592\n",
              "9  0.048692  0.983592"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "NXMvE4yY2F9u",
        "outputId": "fd2facfd-e2c2-4ece-ac9d-c2c771f232f8"
      },
      "source": [
        "#Pero esta vez los fusionaremos uno tras otro para crear un único registro\n",
        "#Recordemos que al usar \"axis = 1\" estamos fusionandolas filas\n",
        "dfDescripcion = pd.concat(array_descripciones, axis = 1)\n",
        "dfDescripcion"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.005324</td>\n",
              "      <td>0.399271</td>\n",
              "      <td>0.430074</td>\n",
              "      <td>0.908842</td>\n",
              "      <td>0.335991</td>\n",
              "      <td>0.945305</td>\n",
              "      <td>0.279429</td>\n",
              "      <td>0.894257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.783567</td>\n",
              "      <td>0.534184</td>\n",
              "      <td>0.281025</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.228656</td>\n",
              "      <td>0.958067</td>\n",
              "      <td>0.121337</td>\n",
              "      <td>0.973564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630632</td>\n",
              "      <td>0.680036</td>\n",
              "      <td>0.231607</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.184308</td>\n",
              "      <td>0.961714</td>\n",
              "      <td>0.089055</td>\n",
              "      <td>0.978122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.525974</td>\n",
              "      <td>0.804011</td>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.157476</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.075063</td>\n",
              "      <td>0.979945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.453674</td>\n",
              "      <td>0.868733</td>\n",
              "      <td>0.183550</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.139054</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.066499</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.919781</td>\n",
              "      <td>0.168534</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.125747</td>\n",
              "      <td>0.973564</td>\n",
              "      <td>0.060816</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.959891</td>\n",
              "      <td>0.156577</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.115612</td>\n",
              "      <td>0.976299</td>\n",
              "      <td>0.056616</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.337906</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.146815</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.107558</td>\n",
              "      <td>0.977211</td>\n",
              "      <td>0.053365</td>\n",
              "      <td>0.984503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.316213</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.138552</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.101016</td>\n",
              "      <td>0.978122</td>\n",
              "      <td>0.050958</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.298730</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.131511</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.095641</td>\n",
              "      <td>0.979034</td>\n",
              "      <td>0.048692</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy      loss  ...  accuracy      loss  accuracy\n",
              "0  1.005324  0.399271  0.430074  ...  0.945305  0.279429  0.894257\n",
              "1  0.783567  0.534184  0.281025  ...  0.958067  0.121337  0.973564\n",
              "2  0.630632  0.680036  0.231607  ...  0.961714  0.089055  0.978122\n",
              "3  0.525974  0.804011  0.203333  ...  0.969918  0.075063  0.979945\n",
              "4  0.453674  0.868733  0.183550  ...  0.970830  0.066499  0.982680\n",
              "5  0.402829  0.919781  0.168534  ...  0.973564  0.060816  0.982680\n",
              "6  0.365800  0.959891  0.156577  ...  0.976299  0.056616  0.982680\n",
              "7  0.337906  0.969918  0.146815  ...  0.977211  0.053365  0.984503\n",
              "8  0.316213  0.971741  0.138552  ...  0.978122  0.050958  0.983592\n",
              "9  0.298730  0.969918  0.131511  ...  0.979034  0.048692  0.983592\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fjPoVM2KEn",
        "outputId": "f4ce4110-ecd3-4efc-f2c9-d08cd4ab047a"
      },
      "source": [
        "#A cada \"loss\" y \"accuracy\" vamos a agregarle por encima su lr\n",
        "#Obtenemos el primer elemento del array de dataframes para obtener los títulos de las columnas\n",
        "columnas_loss_accuracy = array_descripciones[0].columns\n",
        "columnas_loss_accuracy"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['loss', 'accuracy'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hez93L_G2L7Y",
        "outputId": "28023603-3f08-4a97-ef53-e9fbe4449c2d"
      },
      "source": [
        "#Vamos a crear nuevas columnas a nuestro dataframe\n",
        "#Primero colocaremos las columnas que tendrán el nombre de cada lr usado, estos valores están en \"array_lr\"\n",
        "#Luego, para cada \"lr\" vamos a colocarle las columnas \"columnas_loss_accuracy\"\n",
        "#Estas son columnas anidadas, las podemos crear con la función \"MultiIndex\" de Pandas\n",
        "#Por último, con el parámetro \"names\" colocamos el nombre para cada agrupación de columnas\n",
        "nuevas_columnas = pd.MultiIndex.from_product(\n",
        "  [array_lr, columnas_loss_accuracy],\n",
        "  names=['lr', 'metricas']\n",
        ")\n",
        "\n",
        "nuevas_columnas"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiIndex([(0.01,     'loss'),\n",
              "            (0.01, 'accuracy'),\n",
              "            (0.05,     'loss'),\n",
              "            (0.05, 'accuracy'),\n",
              "            ( 0.1,     'loss'),\n",
              "            ( 0.1, 'accuracy'),\n",
              "            ( 0.5,     'loss'),\n",
              "            ( 0.5, 'accuracy')],\n",
              "           names=['lr', 'metricas'])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "VPpFD7O02Qk0",
        "outputId": "208136bb-3b54-472b-e32b-304d04f65f7d"
      },
      "source": [
        "#Colocamos las nuevas columnas a nuestro dataframe\n",
        "dfDescripcion.columns = nuevas_columnas\n",
        "dfDescripcion"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.01</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.05</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.10</th>\n",
              "      <th colspan=\"2\" halign=\"left\">0.50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metricas</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.005324</td>\n",
              "      <td>0.399271</td>\n",
              "      <td>0.430074</td>\n",
              "      <td>0.908842</td>\n",
              "      <td>0.335991</td>\n",
              "      <td>0.945305</td>\n",
              "      <td>0.279429</td>\n",
              "      <td>0.894257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.783567</td>\n",
              "      <td>0.534184</td>\n",
              "      <td>0.281025</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.228656</td>\n",
              "      <td>0.958067</td>\n",
              "      <td>0.121337</td>\n",
              "      <td>0.973564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630632</td>\n",
              "      <td>0.680036</td>\n",
              "      <td>0.231607</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.184308</td>\n",
              "      <td>0.961714</td>\n",
              "      <td>0.089055</td>\n",
              "      <td>0.978122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.525974</td>\n",
              "      <td>0.804011</td>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.157476</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.075063</td>\n",
              "      <td>0.979945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.453674</td>\n",
              "      <td>0.868733</td>\n",
              "      <td>0.183550</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.139054</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.066499</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.919781</td>\n",
              "      <td>0.168534</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.125747</td>\n",
              "      <td>0.973564</td>\n",
              "      <td>0.060816</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.959891</td>\n",
              "      <td>0.156577</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.115612</td>\n",
              "      <td>0.976299</td>\n",
              "      <td>0.056616</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.337906</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.146815</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.107558</td>\n",
              "      <td>0.977211</td>\n",
              "      <td>0.053365</td>\n",
              "      <td>0.984503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.316213</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.138552</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.101016</td>\n",
              "      <td>0.978122</td>\n",
              "      <td>0.050958</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.298730</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.131511</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.095641</td>\n",
              "      <td>0.979034</td>\n",
              "      <td>0.048692</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "lr            0.01                0.05  ...      0.10      0.50          \n",
              "metricas      loss  accuracy      loss  ...  accuracy      loss  accuracy\n",
              "0         1.005324  0.399271  0.430074  ...  0.945305  0.279429  0.894257\n",
              "1         0.783567  0.534184  0.281025  ...  0.958067  0.121337  0.973564\n",
              "2         0.630632  0.680036  0.231607  ...  0.961714  0.089055  0.978122\n",
              "3         0.525974  0.804011  0.203333  ...  0.969918  0.075063  0.979945\n",
              "4         0.453674  0.868733  0.183550  ...  0.970830  0.066499  0.982680\n",
              "5         0.402829  0.919781  0.168534  ...  0.973564  0.060816  0.982680\n",
              "6         0.365800  0.959891  0.156577  ...  0.976299  0.056616  0.982680\n",
              "7         0.337906  0.969918  0.146815  ...  0.977211  0.053365  0.984503\n",
              "8         0.316213  0.971741  0.138552  ...  0.978122  0.050958  0.983592\n",
              "9         0.298730  0.969918  0.131511  ...  0.979034  0.048692  0.983592\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "OcO6Zt0f2S76",
        "outputId": "c40ac395-2bcd-45e9-e4f9-c841c557f6ab"
      },
      "source": [
        "#Vamos a crear el dataframe de \"loss\"\n",
        "#Usaremos la función \"xs\" que nos permite navegar en un dataframe con índices complejos y extraer los campos que queremos\n",
        "#En la función \"xs\" definimos:\n",
        "# 1. El campo que queremos consultar (loss)\n",
        "# 2. De qué subconjunto de campos queremos consultar (level = 'metricas')\n",
        "# 3. Cómo queremos extraer la data (axis = 1, queremos extraerla como columnas)\n",
        "dfLoss = dfDescripcion.xs('loss', level = 'metricas', axis = 1)\n",
        "dfLoss"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>lr</th>\n",
              "      <th>0.01</th>\n",
              "      <th>0.05</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.005324</td>\n",
              "      <td>0.430074</td>\n",
              "      <td>0.335991</td>\n",
              "      <td>0.279429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.783567</td>\n",
              "      <td>0.281025</td>\n",
              "      <td>0.228656</td>\n",
              "      <td>0.121337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630632</td>\n",
              "      <td>0.231607</td>\n",
              "      <td>0.184308</td>\n",
              "      <td>0.089055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.525974</td>\n",
              "      <td>0.203333</td>\n",
              "      <td>0.157476</td>\n",
              "      <td>0.075063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.453674</td>\n",
              "      <td>0.183550</td>\n",
              "      <td>0.139054</td>\n",
              "      <td>0.066499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.402829</td>\n",
              "      <td>0.168534</td>\n",
              "      <td>0.125747</td>\n",
              "      <td>0.060816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.365800</td>\n",
              "      <td>0.156577</td>\n",
              "      <td>0.115612</td>\n",
              "      <td>0.056616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.337906</td>\n",
              "      <td>0.146815</td>\n",
              "      <td>0.107558</td>\n",
              "      <td>0.053365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.316213</td>\n",
              "      <td>0.138552</td>\n",
              "      <td>0.101016</td>\n",
              "      <td>0.050958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.298730</td>\n",
              "      <td>0.131511</td>\n",
              "      <td>0.095641</td>\n",
              "      <td>0.048692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "lr      0.01      0.05      0.10      0.50\n",
              "0   1.005324  0.430074  0.335991  0.279429\n",
              "1   0.783567  0.281025  0.228656  0.121337\n",
              "2   0.630632  0.231607  0.184308  0.089055\n",
              "3   0.525974  0.203333  0.157476  0.075063\n",
              "4   0.453674  0.183550  0.139054  0.066499\n",
              "5   0.402829  0.168534  0.125747  0.060816\n",
              "6   0.365800  0.156577  0.115612  0.056616\n",
              "7   0.337906  0.146815  0.107558  0.053365\n",
              "8   0.316213  0.138552  0.101016  0.050958\n",
              "9   0.298730  0.131511  0.095641  0.048692"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "mLnQfPrL2YJM",
        "outputId": "787422ca-1985-4804-9f61-19e0500d1dee"
      },
      "source": [
        "#Vamos a graficar este dataframe\n",
        "#Recordemos que mientras más pequeño sea el \"loss\" en cada iteración significa que el error se está minimizando\n",
        "#En el eje X colocará los índices de cada iteración\n",
        "#En el eje Y el valor de su \"loss\"\n",
        "#Como son cuatro lr, creará cuatro gráficos\n",
        "dfLoss.plot(ylim=(0,1))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfdddf1710>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1mg97fy2bkn"
      },
      "source": [
        "#INTERPRETACIÓN\n",
        "#Notemos como con un valor muy pequeño para \"lr\" (0.01), el \"loss\" disminuye muy lentamente y va de 0.6 a 0.4\n",
        "#En cambio con un valor muy grande para \"lr\" (0.5), el \"loss\" disminuye más rápidamente y va de 0.2 a casi 0\n",
        "#Eso significa que para este conjunto de datos el \"lr\" se optimiza al aumentarse\n",
        "#Podríamos seguir aumentando el valor de \"lr\" para ver cuál es el límite en dónde ya no podemos optimizar más"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "aQa05LUh2fsj",
        "outputId": "b01c999e-66ae-4b9d-9777-e8a4f4b847d8"
      },
      "source": [
        "#Vamos a crear el dataframe de \"accuracy\"\n",
        "#Usaremos la función \"xs\" que nos permite navegar en un dataframe con índices complejos y extraer los campos que queremos\n",
        "#En la función \"xs\" definimos:\n",
        "# 1. El campo que queremos consultar (accuracy)\n",
        "# 2. De qué subconjunto de campos queremos consultar (level = 'metricas')\n",
        "# 3. Cómo queremos extraer la data (axis = 1, queremos extraerla como columnas)\n",
        "dfAccuracy = dfDescripcion.xs('accuracy', level = 'metricas', axis = 1)\n",
        "dfAccuracy"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>lr</th>\n",
              "      <th>0.01</th>\n",
              "      <th>0.05</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.399271</td>\n",
              "      <td>0.908842</td>\n",
              "      <td>0.945305</td>\n",
              "      <td>0.894257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.534184</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.958067</td>\n",
              "      <td>0.973564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.680036</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.961714</td>\n",
              "      <td>0.978122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.804011</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.979945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.868733</td>\n",
              "      <td>0.968095</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.919781</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.973564</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.959891</td>\n",
              "      <td>0.970830</td>\n",
              "      <td>0.976299</td>\n",
              "      <td>0.982680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.977211</td>\n",
              "      <td>0.984503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.978122</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.969918</td>\n",
              "      <td>0.972653</td>\n",
              "      <td>0.979034</td>\n",
              "      <td>0.983592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "lr      0.01      0.05      0.10      0.50\n",
              "0   0.399271  0.908842  0.945305  0.894257\n",
              "1   0.534184  0.971741  0.958067  0.973564\n",
              "2   0.680036  0.968095  0.961714  0.978122\n",
              "3   0.804011  0.968095  0.969918  0.979945\n",
              "4   0.868733  0.968095  0.970830  0.982680\n",
              "5   0.919781  0.970830  0.973564  0.982680\n",
              "6   0.959891  0.970830  0.976299  0.982680\n",
              "7   0.969918  0.972653  0.977211  0.984503\n",
              "8   0.971741  0.972653  0.978122  0.983592\n",
              "9   0.969918  0.972653  0.979034  0.983592"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "6Q4_GiL42irF",
        "outputId": "12e787b9-6f90-4d57-818b-dda57a7c6077"
      },
      "source": [
        "#Vamos a graficar este dataframe\n",
        "#Recordemos que mientras más pequeño sea el \"accuracy\" en cada iteración significa que los aciertos se están maximizando\n",
        "#En el eje X colocará los índices de cada iteración\n",
        "#En el eje Y el valor de su \"accuracy\"\n",
        "#Como son cuatro lr, creará cuatro gráficos\n",
        "dfAccuracy.plot(ylim=(0,1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfddcdf3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbfbpRJf2nu9"
      },
      "source": [
        "#INTERPRETACIÓN\n",
        "#Notemos como con un valor muy pequeño para \"lr\" (0.01), el \"accuracy\" aumenta en 10 iteraciones hasta un 89%\n",
        "#En cambio con un valor muy grande para \"lr\" (0.5), el \"accuracy\" aumenta en 10 iteraciones hasta un 98%\n",
        "#Eso significa que para este conjunto de datos el \"lr\" se optimiza al aumentarse\n",
        "#Podríamos seguir aumentando el valor de \"lr\" para ver cuál es el límite en dónde ya no podemos optimizar más"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}